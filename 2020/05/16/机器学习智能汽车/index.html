<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Python,机器学习," />










<meta name="description" content="项目背景及意义 “智能+工业”不仅是我国的一个发展战略需求，也是人工智能的热门应用方向之一。智能汽车是一种新型高科技汽车，借助人工智能实现用车保养和零件检测的自动化将会极高地提升车辆的安全程度。除了自动驾驶等智能汽车技术外，特斯拉、宝马等企业正还准备使用人工智能升级以往的车辆故障检测系统，希望实现自动寻找检测汽车某些部件的损坏情况，以便在潜在故障发生之前就对车辆进行检测和维修，甚至在发现问题之后">
<meta property="og:type" content="article">
<meta property="og:title" content="基于人工智能的汽车智能故障诊断系统设计">
<meta property="og:url" content="http://yoursite.com/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/index.html">
<meta property="og:site_name" content="Yixin&#39;s sharing">
<meta property="og:description" content="项目背景及意义 “智能+工业”不仅是我国的一个发展战略需求，也是人工智能的热门应用方向之一。智能汽车是一种新型高科技汽车，借助人工智能实现用车保养和零件检测的自动化将会极高地提升车辆的安全程度。除了自动驾驶等智能汽车技术外，特斯拉、宝马等企业正还准备使用人工智能升级以往的车辆故障检测系统，希望实现自动寻找检测汽车某些部件的损坏情况，以便在潜在故障发生之前就对车辆进行检测和维修，甚至在发现问题之后">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/2.png">
<meta property="og:image" content="http://yoursite.com/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/3.png">
<meta property="og:image" content="http://yoursite.com/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/4.png">
<meta property="article:published_time" content="2020-05-16T15:41:41.000Z">
<meta property="article:modified_time" content="2020-06-16T10:51:45.000Z">
<meta property="article:author" content="Ren Yixin">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/2.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/05/16/机器学习智能汽车/"/>





  <title>基于人工智能的汽车智能故障诊断系统设计 | Yixin's sharing</title>
  








<meta name="generator" content="Hexo 4.2.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Yixin's sharing</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ren Yixin">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Yixin's sharing">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">基于人工智能的汽车智能故障诊断系统设计</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-16T23:41:41+08:00">
                2020-05-16
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">科研笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  5.5k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  24
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="项目背景及意义"><a class="markdownIt-Anchor" href="#项目背景及意义"></a> <strong>项目背景及意义</strong></h3>
<p>“智能+工业”不仅是我国的一个发展战略需求，也是人工智能的热门应用方向之一。智能汽车是一种新型高科技汽车，借助人工智能实现用车保养和零件检测的自动化将会极高地提升车辆的安全程度。除了自动驾驶等智能汽车技术外，特斯拉、宝马等企业正还准备使用人工智能升级以往的车辆故障检测系统，希望实现自动寻找检测汽车某些部件的损坏情况，以便在潜在故障发生之前就对车辆进行检测和维修，甚至在发现问题之后，配合自动驾驶系统让车辆自行驾驶至服务中心。</p>
<p>本文中我们将采用使用人工智能的方法构建一套模型，通过智能汽车内零部件传感器的数据，运用机器学习进行建模分析，构建一套汽车智能故障诊断系统，从而帮助车厂判断汽车的健康状况。</p>
<h3 id="相关概念"><a class="markdownIt-Anchor" href="#相关概念"></a> <strong>相关概念</strong></h3>
<h4 id="汽车传感器智能汽车的感知和计算"><a class="markdownIt-Anchor" href="#汽车传感器智能汽车的感知和计算"></a> 汽车传感器：智能汽车的感知和计算</h4>
<p>传感器是一种检测装置，能够感受到被测量的信息，并能将感受到的信息按照一定规律转变为电信号或其他所需形式的信息输出，满足信息的传输、处理、存储、显示、记录和控制等要求。汽车传感器可分为车辆感知、环境感知两大类。动力、底盘、车身及电子电气系统中的传感器属于车辆感知范畴，ADAS 以及无人驾驶系统中引入的车载摄像头、毫米波雷达、激光雷达等属于环境感知范畴。传感器作为智能汽车感知环境的硬件基础，在智能驾驶发展过程中起着重要作用[<a href="#_edn1">i]</a>。</p>
<p>![智能汽车传感系统](机器学习智能汽车/图片 1.png)</p>
<p>本项目中，我们可以借助车辆感知大类的传感器收集汽车运行中的各种工况信息，如车速、各种介质的温度、发动机运转工况、各部位压力等。将他们转化成电讯号输给计算机，远程分析车辆的健康状况。</p>
<h4 id="机器学习"><a class="markdownIt-Anchor" href="#机器学习"></a> <strong>机器学习</strong></h4>
<p>机器学习是一门涉及多领域的交叉学科，其研究内容涉及概率论，统计学，算法复杂度，线性代数，微积分等众多领域。机器学习研究的是计算机如何模拟人类的学习行为，从相应的数据中学习到一定的规律，并能够对新的数据进行分析。目前十分火热的深度学习就是机器学习的一个分支，机器学习在众多现代计算机 领域有着十分重要的作用，比如图像处理，语音识别，自然语言处理等等。机器学习分监督学习，无监督学习，半监督学习。使用机器学习可以对数据进行分类，回归等等分析。常用的机器学习算法有:线性回归，逻辑斯蒂回归，cart 决策树，随机森林，Adaboosting，bagging，SVM，k-means，PCA等等算法。本文将通过集成学习的方法，同时根据实际业务问题调整阈值，对车辆传感器的数据进行分析，确保将健康状况不良好的汽车即使召回。</p>
<h3 id="汽车传感器数据分析"><a class="markdownIt-Anchor" href="#汽车传感器数据分析"></a> <strong>汽车传感器数据分析</strong></h3>
<h4 id="数据探索和方法选择"><a class="markdownIt-Anchor" href="#数据探索和方法选择"></a> 数据探索和方法选择</h4>
<p>我手上的训练集共有60000条训练样本，测试集共有16000条训练样本。每个数据一共有171个特征，由于数据提供方的原因，数据的特征是匿名的。其中有的特征是数值连续特征，有的特征是对数据特征进行了histograms处理。缺失数据表示为NaN。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 导入依赖库</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">import pandas as pd</span><br><span class="line">import numpy as np</span><br><span class="line">import warnings</span><br><span class="line">warnings.filterwarnings(&quot;ignore&quot;)</span><br><span class="line">#加载数据</span><br><span class="line">train &#x3D; pd.read_csv(&#39;train_set.csv&#39;,na_values&#x3D;&#39;na&#39;)</span><br><span class="line">test &#x3D; pd.read_csv(&#39;test_set.csv&#39;,na_values&#x3D;&#39;na&#39;)</span><br><span class="line">#查看数据的shape</span><br><span class="line">print(&#39;训练集的形状：&#123;&#125;&#39;.format(train.shape))</span><br><span class="line">print(&#39;测试集的形状：&#123;&#125;&#39;.format(test.shape))</span><br><span class="line"></span><br><span class="line"># TODO：打印train前五行数据</span><br><span class="line">train.head()</span><br><span class="line"># TODO：打印test前五行数据</span><br><span class="line">test.head()</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/2.png" alt="前5行数据的部分特征"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># TODO：查看train数据中class这列的类别比例</span><br><span class="line">pd.value_counts(train[&#39;class&#39;])</span><br></pre></td></tr></table></figure>
<p>通过查看数据类别，我发现训练集共60000个样本中，有59000条是正常样本，只有1000条是故障车辆样本。此问题是一个典型的样本不均衡问题，对于这种非常不均衡的问题一般有两种解决思路：</p>
<p>（1）使用异常值检测的方法：将少类的样本看作异常值</p>
<p>（2）使用监督学习的方法，看作分类问题。</p>
<p>本文中我将使用监督学习的方法来对他们进行建模。</p>
<h4 id="数据预处理"><a class="markdownIt-Anchor" href="#数据预处理"></a> 数据预处理</h4>
<p>对于传感器的原始数据数据，我按顺序进行以下预处理:</p>
<h5 id="区分特征值和标签"><a class="markdownIt-Anchor" href="#区分特征值和标签"></a> 区分特征值和标签</h5>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 将特征和标签划分开</span><br><span class="line"># 在这一步中我们将把feature和label分开</span><br><span class="line">train_feature  &#x3D; train[train.columns.difference([&#39;class&#39;])]</span><br><span class="line">train_label &#x3D; train[&#39;class&#39;]</span><br><span class="line"></span><br><span class="line">test_feature  &#x3D; test[test.columns.difference([&#39;class&#39;])]</span><br><span class="line">test_label &#x3D; test[&#39;class&#39;]</span><br></pre></td></tr></table></figure>
<h5 id="区分数据特征类型"><a class="markdownIt-Anchor" href="#区分数据特征类型"></a> 区分数据特征类型：</h5>
<p>如前文所述，传感器数据分为两类，一类是数值特征，一类是通过直方图得到的分布特征。由于直方图类数据在特征选择时要进行特殊的处理，因此第一步是通过通过正则表达式，自动匹配这类分布特征的字段类型，进行查找和筛选。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">pattern &#x3D; re.compile(&#39;[a-z]*_001&#39;)</span><br><span class="line">col_bin_name &#x3D; [re.findall(pattern,char) for char in train_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">bin_name_lst &#x3D; []</span><br><span class="line">for col in col_bin_name:</span><br><span class="line">    pattern &#x3D; re.compile(col[0][:2]+&#39;_[0-9]*&#39;)</span><br><span class="line">    find_name &#x3D; [re.findall(pattern,char) for char in train_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">    bin_name_lst.append(np.concatenate(find_name,axis&#x3D;0))</span><br><span class="line">    print(find_name)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/3.png" alt="打印出所有直方图类的特征"></p>
<h5 id="标签数据转换"><a class="markdownIt-Anchor" href="#标签数据转换"></a> 标签数据转换：</h5>
<p>neg意味着汽车的健康状况为良好，不需要检修；pos为状况不良，需要检修。为了便于计算，我将neg标签转换为0，pos标签转换为1。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_label &#x3D; train_label.map(&#123;&#39;pos&#39;:1,&#39;neg&#39;:0&#125;)</span><br><span class="line">test_label &#x3D; test_label.map(&#123;&#39;pos&#39;:1,&#39;neg&#39;:0&#125;)</span><br></pre></td></tr></table></figure>
<h5 id="数据缺失值填充"><a class="markdownIt-Anchor" href="#数据缺失值填充"></a> 数据缺失值填充：</h5>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># TODO：统计训练集和测试集分别有多少行有缺失</span><br><span class="line">print(&#39;训练集缺失&#39;,(train.isnull().sum(axis&#x3D;1)&gt;0).sum(),&#39;行&#39;)</span><br><span class="line">print(&#39;训练集缺失&#39;,(train.isnull().sum(axis&#x3D;0)&gt;0).sum(),&#39;列&#39;)</span><br><span class="line"># TODO：统计训练集和测试集分别有多少列有缺失</span><br><span class="line">print(&#39;测试集缺失&#39;,(test.isna().sum(axis&#x3D;1)&gt;0).sum(),&#39;行&#39;)</span><br><span class="line">print(&#39;测试集缺失&#39;,(test.isnull().sum(axis&#x3D;0)&gt;0).sum(),&#39;列&#39;)</span><br></pre></td></tr></table></figure>
<p>对数据进行缺失值的分析，发现训练集共缺失 59409 行，169 列；测试集缺失 15835 行，169 列。可以判断有大量的缺失值，因此不能进行简单地丢弃，而是需要进行填充。填充的方法有均值填充和模型填充。在计算效果上，模型填充更优，但计算量较大。此处我们使用均值填充。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 使用训练集的均值进行填充</span><br><span class="line">for col in train_feature.columns:</span><br><span class="line">    train_feature[col] &#x3D; train_feature[col].fillna(train_feature[col].mean())</span><br><span class="line"></span><br><span class="line">for col in test_feature.columns:</span><br><span class="line">    test_feature[col] &#x3D; test_feature[col].fillna(train_feature[col].mean())</span><br></pre></td></tr></table></figure>
<h5 id="特征工程"><a class="markdownIt-Anchor" href="#特征工程"></a> 特征工程：</h5>
<p>虽然大部分的数据都只有匿名的特征，但仍然可以对直方图特征做一些特征的抽取工作。对于直方图特征，可以想象，每个直方图的bins的和表示了这个车辆检查这个特征的次数，那么显然这个数字的和越大就代表这个车子检查这个特征的次数越多，也间接的表明了这个车子到目前为止的使用寿命；直方图表示了这个特征的分布，可以通过JS散度和推土机距离来度量分布之间的距离来成为一个新的特征。因此本项目中，我选择以下几种基准分布：</p>
<p>（1）正样本的每个直方图特征的均值分布。</p>
<p>（2）负样本的每个直方图特征的均值分布。</p>
<p>（3）一个正态分布。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">## 特征抽取一：</span><br><span class="line">train_feature_extract &#x3D; pd.DataFrame(index&#x3D;train_feature.index)</span><br><span class="line">for index,col in enumerate(col_bin_name):</span><br><span class="line">    pattern &#x3D; re.compile(col[0][:2]+&#39;_[0-9]*&#39;)</span><br><span class="line">    find_name &#x3D; [re.findall(pattern,char) for char in train_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">    name &#x3D; &#39;sum_bins_&#39;+str(index)</span><br><span class="line">    train_feature_extract[name] &#x3D; train_feature[np.concatenate(find_name,axis&#x3D;0)].sum(axis&#x3D;1)</span><br><span class="line">train_feature_extract[&#39;bins_max&#39;] &#x3D; train_feature_extract.max(axis&#x3D;1)</span><br><span class="line"></span><br><span class="line">test_feature_extract &#x3D; pd.DataFrame(index&#x3D;test_feature.index)</span><br><span class="line">for index,col in enumerate(col_bin_name):</span><br><span class="line">    pattern &#x3D; re.compile(col[0][:2]+&#39;_[0-9]*&#39;)</span><br><span class="line">    find_name &#x3D; [re.findall(pattern,char) for char in test_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">    name &#x3D; &#39;sum_bins_&#39;+str(index)</span><br><span class="line">    test_feature_extract[name] &#x3D; test_feature[np.concatenate(find_name,axis&#x3D;0)].sum(axis&#x3D;1)</span><br><span class="line">test_feature_extract[&#39;bins_max&#39;] &#x3D; test_feature_extract.max(axis&#x3D;1)</span><br><span class="line"></span><br><span class="line">## 把特征分为数值特征和直方图特征两部分</span><br><span class="line">train_num_feature &#x3D; train_feature[train_feature.columns.difference(np.concatenate(bin_name_lst,axis&#x3D;0))];</span><br><span class="line">train_bin_feature &#x3D; train_feature[np.concatenate(bin_name_lst,axis&#x3D;0)];</span><br><span class="line"></span><br><span class="line">test_num_feature &#x3D; test_feature[test_feature.columns.difference(np.concatenate(bin_name_lst,axis&#x3D;0))];</span><br><span class="line">test_bin_feature &#x3D; test_feature[np.concatenate(bin_name_lst,axis&#x3D;0)];</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">## 特征抽取二：</span><br><span class="line">## 生成基准分布</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"># pos均匀分布</span><br><span class="line"># neg均匀分布</span><br><span class="line">pos_distribution_mean &#x3D; []</span><br><span class="line">neg_distribution_mean &#x3D; []</span><br><span class="line">for index,col in enumerate(col_bin_name):</span><br><span class="line">    pattern &#x3D; re.compile(col[0][:2]+&#39;_[0-9]*&#39;)</span><br><span class="line">    find_name &#x3D; [re.findall(pattern,char) for char in train_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">    pos &#x3D; train_bin_feature.iloc[train_label[train_label&#x3D;&#x3D;1].index.tolist()][np.concatenate(find_name,axis&#x3D;0)]</span><br><span class="line">    neg &#x3D; train_bin_feature.iloc[train_label[train_label&#x3D;&#x3D;0].index.tolist()][np.concatenate(find_name,axis&#x3D;0)]</span><br><span class="line">    pos_distribution_mean.append(pos.sum(axis&#x3D;0))</span><br><span class="line">    neg_distribution_mean.append(neg.sum(axis&#x3D;0))</span><br><span class="line"></span><br><span class="line"># 高斯分布</span><br><span class="line">gs_distribution_sample &#x3D; np.random.normal(loc&#x3D;5.0, scale&#x3D;1.5,size&#x3D;500000)</span><br><span class="line">gs_distribution &#x3D; plt.hist(gs_distribution_sample,bins&#x3D;10)[0]</span><br><span class="line"></span><br><span class="line"># 分布归一化</span><br><span class="line">pos_dis &#x3D; [pos&#x2F;pos.sum() for pos in pos_distribution_mean];</span><br><span class="line">neg_dis &#x3D; [neg&#x2F;neg.sum() for neg in neg_distribution_mean];</span><br><span class="line">gs_distribution &#x3D; gs_distribution&#x2F;gs_distribution.sum()</span><br><span class="line"></span><br><span class="line">## 定义wasserstein距离(推土机距离)和JS散度</span><br><span class="line">from scipy.stats import entropy</span><br><span class="line">from scipy.stats import wasserstein_distance</span><br><span class="line">def js_dis(x,q):</span><br><span class="line">    M&#x3D;(x+q)&#x2F;2</span><br><span class="line">    js2&#x3D;0.5*entropy(x, M)+0.5*entropy(q, M)</span><br><span class="line">    return js2</span><br><span class="line">def ws_dis(x,q):</span><br><span class="line">    return wasserstein_distance(x,q)</span><br><span class="line">    </span><br><span class="line">## 特征抽取二：</span><br><span class="line">## 没有tqdm的需要先安装tqdm这个包。</span><br><span class="line">## 这个步骤的计算时间非常长，请耐心等待。</span><br><span class="line">## 训练集的特征抽取</span><br><span class="line">from tqdm import tqdm</span><br><span class="line">name_number &#x3D; 1</span><br><span class="line">for index,col in tqdm(enumerate(col_bin_name)):</span><br><span class="line">    pattern &#x3D; re.compile(col[0][:2]+&#39;_[0-9]*&#39;)</span><br><span class="line">    find_name &#x3D; [re.findall(pattern,char) for char in train_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">    temp &#x3D; train_bin_feature[np.concatenate(find_name,axis&#x3D;0)]</span><br><span class="line">    temp &#x3D; temp.apply(lambda x:x&#x2F;x.sum(),axis&#x3D;1)</span><br><span class="line">    for pos in pos_dis:</span><br><span class="line">        train_feature_extract[name_number] &#x3D; temp.apply(js_dis,axis&#x3D;1,args&#x3D;(pos.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">        train_feature_extract[name_number] &#x3D; temp.apply(ws_dis,axis&#x3D;1,args&#x3D;(pos.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">    for neg in neg_dis:</span><br><span class="line">        train_feature_extract[name_number] &#x3D; temp.apply(js_dis,axis&#x3D;1,args&#x3D;(neg.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">        train_feature_extract[name_number] &#x3D; temp.apply(ws_dis,axis&#x3D;1,args&#x3D;(neg.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">    train_feature_extract[name_number] &#x3D; temp.apply(js_dis,axis&#x3D;1,args&#x3D;(gs_distribution,))</span><br><span class="line">    name_number+&#x3D;1</span><br><span class="line">    train_feature_extract[name_number] &#x3D; temp.apply(ws_dis,axis&#x3D;1,args&#x3D;(gs_distribution,))</span><br><span class="line">    name_number+&#x3D;1    </span><br><span class="line">## 测试集的特征抽取</span><br><span class="line">name_number &#x3D; 1</span><br><span class="line">for index,col in tqdm(enumerate(col_bin_name)):</span><br><span class="line">    pattern &#x3D; re.compile(col[0][:2]+&#39;_[0-9]*&#39;)</span><br><span class="line">    find_name &#x3D; [re.findall(pattern,char) for char in test_feature.columns.tolist() if len(re.findall(pattern,char))!&#x3D;0]</span><br><span class="line">    temp &#x3D; test_bin_feature[np.concatenate(find_name,axis&#x3D;0)]</span><br><span class="line">    temp &#x3D; temp.apply(lambda x:x&#x2F;x.sum(),axis&#x3D;1)</span><br><span class="line">    for pos in pos_dis:</span><br><span class="line">        test_feature_extract[name_number] &#x3D; temp.apply(js_dis,axis&#x3D;1,args&#x3D;(pos.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">        test_feature_extract[name_number] &#x3D; temp.apply(ws_dis,axis&#x3D;1,args&#x3D;(pos.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">    for neg in neg_dis:</span><br><span class="line">        test_feature_extract[name_number] &#x3D; temp.apply(js_dis,axis&#x3D;1,args&#x3D;(neg.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">        test_feature_extract[name_number] &#x3D; temp.apply(ws_dis,axis&#x3D;1,args&#x3D;(neg.values,))</span><br><span class="line">        name_number+&#x3D;1</span><br><span class="line">    test_feature_extract[name_number] &#x3D; temp.apply(js_dis,axis&#x3D;1,args&#x3D;(gs_distribution,))</span><br><span class="line">    name_number+&#x3D;1</span><br><span class="line">    test_feature_extract[name_number] &#x3D; temp.apply(ws_dis,axis&#x3D;1,args&#x3D;(gs_distribution,))</span><br><span class="line">    name_number+&#x3D;1</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">print(train_feature_extract.shape)</span><br><span class="line">print(test_feature_extract.shape)</span><br><span class="line">## 抽取完特征后，会发现部分特征是nan或者inf，这是由于在计算分布距离的时候有的分布是0导致的</span><br><span class="line">## 所以我们需要对抽取后的nan、inf这部分数据进行变换</span><br><span class="line"></span><br><span class="line">train_feature_extract &#x3D; train_feature_extract.fillna(-1)</span><br><span class="line">test_feature_extract &#x3D; test_feature_extract.fillna(-1)</span><br><span class="line"></span><br><span class="line">def f_inf(x):</span><br><span class="line">    if x&#x3D;&#x3D;np.inf:</span><br><span class="line">        return -2</span><br><span class="line">    else:</span><br><span class="line">        return x</span><br><span class="line">train_feature_extract &#x3D; train_feature_extract.applymap(f_inf)</span><br><span class="line">test_feature_extract &#x3D; test_feature_extract.applymap(f_inf)</span><br></pre></td></tr></table></figure>
<h4 id="模型设计和集成"><a class="markdownIt-Anchor" href="#模型设计和集成"></a> 模型设计和集成</h4>
<p>处理好数据之后使用数据对模型进行训练模型，此处我选择了Logistic 回归、决策树和随机森林三个基础模型，并根据使用交叉验证和网格搜索选择合适的参数。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">## 模型选择、交叉验证、网格搜索</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">from sklearn.metrics import roc_auc_score, make_scorer</span><br><span class="line">from sklearn.linear_model import LogisticRegression</span><br><span class="line">#网格搜索：逻辑斯特回归</span><br><span class="line">param&#x3D;&#123; &#39;C&#39;:[0.0001,0.001,0.01,0.1,0.5,1.0]&#125;</span><br><span class="line">Grid2&#x3D;GridSearchCV(estimator&#x3D;LogisticRegression(),param_grid&#x3D;param,scoring&#x3D;make_scorer(roc_auc_score))</span><br><span class="line">Grid2.fit(train_feature_extract, train_label)</span><br><span class="line">print(f&quot;逻辑斯特回归交叉验证中测试的最优参数：&#123;Grid2.best_params_&#125;&quot;)</span><br><span class="line">print(f&quot;逻辑斯特回归交叉验证中AUC最高得分：&#123;Grid2.best_score_&#125;&quot;)</span><br><span class="line">best_model_lgr &#x3D; Grid2.best_estimator_</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#网格搜索：决策树</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">parameters &#x3D; &#123;&#39;max_depth&#39;:[3, 5, 7, 9],&#39;min_samples_leaf&#39;: [1, 2, 3, 4]&#125;# 选择两个超参数 树的深度max_depth和叶子的最小值min_samples_leaf</span><br><span class="line">Grid1 &#x3D; GridSearchCV(estimator&#x3D;DecisionTreeClassifier(random_state&#x3D;0), param_grid&#x3D;parameters,scoring &#x3D; make_scorer(roc_auc_score),cv&#x3D;3)# 进行网格搜索得到最优参数组合</span><br><span class="line">Grid1.fit(train_feature_extract, train_label) #通过有最优参数组合的最优模型进行训练</span><br><span class="line">print(f&quot;决策树交叉验证中测试的最优参数：&#123;Grid1.best_params_&#125;&quot;)</span><br><span class="line">print(f&quot;决策树交叉验证中AUC最高得分：&#123;Grid1.best_score_&#125;&quot;)</span><br><span class="line">best_model_dtc &#x3D; Grid1.best_estimator_</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">#随机森林很多内部变量的网格搜索</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">#首先对n_estimators进行网格搜索：</span><br><span class="line">param_test1 &#x3D; &#123;&#39;n_estimators&#39;:[20,30,40,50]&#125;</span><br><span class="line">gsearch1 &#x3D; GridSearchCV(estimator &#x3D; RandomForestClassifier(min_samples_split&#x3D;100,</span><br><span class="line">                                  min_samples_leaf&#x3D;20,max_depth&#x3D;8,max_features&#x3D;&#39;sqrt&#39; ,random_state&#x3D;10), </span><br><span class="line">                       param_grid &#x3D; param_test1, scoring&#x3D;&#39;roc_auc&#39;,cv&#x3D;5)</span><br><span class="line">gsearch1.fit(train_feature_extract,train_label)</span><br><span class="line">print( gsearch1.best_params_, gsearch1.best_score_)#,gsearch1.cv_results_打印拟合结果)</span><br><span class="line">#接着对决策树最大深度max_depth进行网格搜索。</span><br><span class="line">param_test2 &#x3D; &#123;&#39;max_depth&#39;:[1,2,3,5,7,9,11,13]&#125;</span><br><span class="line">gsearch2 &#x3D; GridSearchCV(estimator &#x3D; RandomForestClassifier(n_estimators&#x3D;50, min_samples_split&#x3D;100,</span><br><span class="line">                                  min_samples_leaf&#x3D;20,max_features&#x3D;&#39;sqrt&#39; ,oob_score&#x3D;True, random_state&#x3D;10),</span><br><span class="line">param_grid &#x3D; param_test2, scoring&#x3D;&#39;roc_auc&#39;,iid&#x3D;False, cv&#x3D;5)</span><br><span class="line">gsearch2.fit(train_feature_extract,train_label)</span><br><span class="line">print( gsearch2.best_params_, gsearch2.best_score_)</span><br><span class="line">#得到max_depth&#x3D;5。</span><br><span class="line">#下面再对内部节点再划分所需最小样本数min_samples_split和叶子节点最少样本数min_samples_leaf一起调参。</span><br><span class="line">param_test3 &#x3D; &#123;&#39;min_samples_split&#39;:[80,100,150], &#39;min_samples_leaf&#39;:[10,20,50,100]&#125;</span><br><span class="line">gsearch3 &#x3D; GridSearchCV(estimator &#x3D; RandomForestClassifier(n_estimators&#x3D; 50, max_depth&#x3D;5,</span><br><span class="line">                                  max_features&#x3D;&#39;sqrt&#39; ,oob_score&#x3D;True, random_state&#x3D;10),</span><br><span class="line">   param_grid &#x3D; param_test3, scoring&#x3D;&#39;roc_auc&#39;,iid&#x3D;False, cv&#x3D;5)</span><br><span class="line">gsearch3.fit(train_feature_extract,train_label)</span><br><span class="line">print( gsearch3.best_params_, gsearch3.best_score_)</span><br><span class="line">#得到min_samples_split&#x3D;50和min_samples_leaf&#x3D;150</span><br><span class="line">#再对最大特征数max_features做调参:</span><br><span class="line">param_test4 &#x3D; &#123;&#39;max_features&#39;:[3,5,7,9,11]&#125;</span><br><span class="line">gsearch4 &#x3D; GridSearchCV(estimator &#x3D; RandomForestClassifier(n_estimators&#x3D; 50, max_depth&#x3D;5, min_samples_split&#x3D;150,</span><br><span class="line">                                  min_samples_leaf&#x3D;50 ,oob_score&#x3D;True, random_state&#x3D;10),</span><br><span class="line">   param_grid &#x3D; param_test4, scoring&#x3D;&#39;roc_auc&#39;,iid&#x3D;False, cv&#x3D;5)</span><br><span class="line">gsearch4.fit(train_feature_extract,train_label)</span><br><span class="line">print( gsearch4.best_params_, gsearch4.best_score_)</span><br><span class="line">#得到&#39;max_features&#39;&#x3D;9</span><br><span class="line">#用我们搜索到的最佳参数，我们再看看最终随机森林的模型拟合：</span><br><span class="line">rf2 &#x3D; RandomForestClassifier(n_estimators&#x3D; 50, max_depth&#x3D;5, min_samples_split&#x3D;150,</span><br><span class="line">                                  min_samples_leaf&#x3D;50,max_features&#x3D;9, oob_score&#x3D;True, random_state&#x3D;10)</span><br><span class="line">rf2.fit(train_feature_extract,train_label)</span><br><span class="line">best_model_rfc &#x3D; rf2</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import confusion_matrix</span><br><span class="line">from sklearn.metrics import roc_auc_score</span><br><span class="line">#测试集上结果</span><br><span class="line">print(f&quot;决策树测试集上的AUC是:&#123;roc_auc_score(test_label,best_model_dtc.predict(test_feature_extract))&#125;&quot;)</span><br><span class="line">print(f&quot;逻辑斯特回归测试集上的AUC是:&#123;roc_auc_score(test_label,best_model_lgr.predict(test_feature_extract))&#125;&quot;)</span><br><span class="line">print(f&quot;随机森林回归测试集上的AUC是:&#123;roc_auc_score(test_label, best_model_rfc.predict(test_feature_extract))&#125;&quot;)</span><br></pre></td></tr></table></figure>
<p>结果显示，在训练集上使用Logistic回归得到的AUC参数为0.606，决策树得到的AUC为0.644，略高于Logistic回归，通过随机森林得到的AUC为0.969。</p>
<p>验证集上的结果分别为：决策树AUC 0.744，逻辑斯特回归测试集上的AUC是:0.762，随机森林回归测试集上的AUC是:0.660。随机森林在训练集和测试集上差异大的原因可能是出现了过拟合。</p>
<p>除了直接查看AUC，还可以通过用AUC=0.5作为阈值看结果的混淆矩阵，同时设计一个随机猜测函数作为baseline来进一步查看模型相对于随机猜测时候的优势。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#查看以0.5作为阈值的混淆矩阵</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line">true&#x3D;test_label</span><br><span class="line">pred1&#x3D;Grid1.predict(test_feature_extract)</span><br><span class="line">pred2&#x3D;Grid2.predict(test_feature_extract)</span><br><span class="line">pred3&#x3D;best_model_rfc.predict(test_feature_extract)</span><br><span class="line">#导入混淆矩阵函数</span><br><span class="line">cm1&#x3D;confusion_matrix(true,pred1)</span><br><span class="line">cm2&#x3D;confusion_matrix(true,pred2)</span><br><span class="line">cm3&#x3D;confusion_matrix(true,pred3)</span><br><span class="line">#导入作图函数</span><br><span class="line">plt.matshow(cm1,cmap&#x3D;plt.cm.Greens)</span><br><span class="line">sns.heatmap(cm1,annot&#x3D;True)</span><br><span class="line">plt.matshow(cm2,cmap&#x3D;plt.cm.Greens)</span><br><span class="line">sns.heatmap(cm2,annot&#x3D;True)</span><br><span class="line">plt.matshow(cm3,cmap&#x3D;plt.cm.Greens)</span><br><span class="line">sns.heatmap(cm3,annot&#x3D;True)</span><br><span class="line">#输出为混淆矩阵</span><br><span class="line">#TODO：随机猜测函数</span><br><span class="line">random&#x3D; np.random.randint(0,2,16000)</span><br><span class="line">cm0&#x3D;confusion_matrix(true,random)</span><br><span class="line">plt.matshow(cm0,cmap&#x3D;plt.cm.Greens)</span><br><span class="line">sns.heatmap(cm0,annot&#x3D;True)</span><br></pre></td></tr></table></figure>
<p>![混淆矩阵:左上（决策树）右上（Logistic）左下（随机森林）右下（随机猜测）](机器学习智能汽车/屏幕快照 2020-05-16 下午11.45.35.png)</p>
<p>在训练完单个模型之后，我们将进行模型的集成。集成技术是将多个分类器的结果或性能结合起来，以提高单个分类器的性能。该方法通过装配不同的分类器来修改单个分类器的归纳能力[<a href="#_edn2">ii]</a>，也能更好地解决样本不均衡的问题。此处，我们使用stacking的方法对步骤四生成的不同学习器进行集成，同时画出集成后模型的ROC曲线。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">## TODO:模型集成</span><br><span class="line">from mlxtend.classifier import EnsembleVoteClassifier</span><br><span class="line">from mlxtend.data import iris_data</span><br><span class="line">clf1&#x3D;best_model_dtc</span><br><span class="line">clf2&#x3D;best_model_lgr</span><br><span class="line">clf3&#x3D;best_model_rfc</span><br><span class="line">eclf&#x3D;EnsembleVoteClassifier(clfs&#x3D;[clf1, clf2,clf3],</span><br><span class="line">                              weights&#x3D;[2,1,1], voting&#x3D;&#39;soft&#39;)</span><br><span class="line">eclf.fit(train_feature_extract,train_label)</span><br><span class="line">## TODO：ROC曲线</span><br><span class="line"></span><br><span class="line">from sklearn.metrics import roc_curve, auc</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from sklearn.model_selection import StratifiedKFold</span><br><span class="line"></span><br><span class="line">probas_ &#x3D; eclf.predict_proba(test_feature_extract) # 训练模型后预测每条样本得到两种结果的概率</span><br><span class="line">fpr, tpr, thresholds &#x3D; roc_curve(test_label, probas_[:, 1])    # 该函数得到伪正例、真正例、阈值，这里只使用前两个</span><br><span class="line">roc_auc &#x3D; auc(fpr, tpr)  # 求auc面积</span><br><span class="line">plt.plot(fpr, tpr, lw&#x3D;1, label&#x3D;&#39;ROC (area &#x3D; &#123;1:.2f&#125;)&#39;.format(i, roc_auc))    # 画出当前分割数据的ROC曲线</span><br><span class="line"> </span><br><span class="line">plt.plot([0, 1], [0, 1], &#39;--&#39;, color&#x3D;(0.6, 0.6, 0.6), label&#x3D;&#39;Luck&#39;) # 画对角线</span><br><span class="line">plt.xlim([-0.05, 1.05])     # 设置x、y轴的上下限，设置宽一点，以免和边缘重合，可以更好的观察图像的整体</span><br><span class="line">plt.ylim([-0.05, 1.05])</span><br><span class="line">plt.xlabel(&#39;False Positive Rate&#39;)</span><br><span class="line">plt.ylabel(&#39;True Positive Rate&#39;)    # 可以使用中文，但需要导入一些库即字体</span><br><span class="line">plt.title(&#39;ROC curve&#39;)</span><br><span class="line">plt.legend(loc&#x3D;&quot;lower right&quot;)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2020/05/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%99%BA%E8%83%BD%E6%B1%BD%E8%BD%A6/4.png" alt="集成后模型的ROC曲线"></p>
<h3 id="结果分析"><a class="markdownIt-Anchor" href="#结果分析"></a> <strong>结果分析</strong></h3>
<p>在实际的业务问题中，不能简单的通过准确率，召回率或者精确率来评估阈值。换言之，对于口碑至上的名车厂而言，对miss fault（把健康状况不良的车辆看成好的）的容忍度对falsely predict（把健康状况良好的汽车错误当成不好的）的容忍度要低很多。前者意味着安全和品牌的声誉，后者只是需要额外付出财力。这两者之间的代价关系和权重需要有专门的研究。</p>
<p>在这个问题中，我们简单地把$ miss fault <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">代</mi><mi mathvariant="normal">价</mi><mi mathvariant="normal">是</mi><mn>500</mn><mi mathvariant="normal">，</mi></mrow><annotation encoding="application/x-tex">代价是500，</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord cjk_fallback">代</span><span class="mord cjk_fallback">价</span><span class="mord cjk_fallback">是</span><span class="mord">5</span><span class="mord">0</span><span class="mord">0</span><span class="mord cjk_fallback">，</span></span></span></span>falsely$ <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">predict</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="mord mathdefault">e</span><span class="mord mathdefault">d</span><span class="mord mathdefault">i</span><span class="mord mathdefault">c</span><span class="mord mathdefault">t</span></span></span></span>代价是10，那么我们需要找到一个阈值，使得总代价$ cost $最小。</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>=</mo><mn>1000</mn><mo>∗</mo><mi>n</mi><mi>u</mi><msub><mi>m</mi><mi>m</mi></msub><mi>f</mi><mo>+</mo><mn>10</mn><mo>∗</mo><mi>n</mi><mi>u</mi><msub><mi>m</mi><mi>f</mi></msub><mi>p</mi></mrow><annotation encoding="application/x-tex">cost=1000*num_mf+10*num_fp
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.61508em;vertical-align:0em;"></span><span class="mord mathdefault">c</span><span class="mord mathdefault">o</span><span class="mord mathdefault">s</span><span class="mord mathdefault">t</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361079999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord mathdefault">p</span></span></span></span></span></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">## TODO：找阈值使得cost最小</span><br><span class="line">thresholds&#x3D;[0.8,0.81,0.812,0.813,0.814,0.815,0.816,0.817,0.818,0.819,0.82]</span><br><span class="line">cost&#x3D;500*16000</span><br><span class="line">for i in thresholds:</span><br><span class="line">    probas_ &#x3D; eclf.predict_proba(test_feature_extract) # 训练模型后预测每条样本得到两种结果的概率</span><br><span class="line">    arr&#x3D;probas_[:,1]</span><br><span class="line">    arr[arr &gt; i] &#x3D; 1</span><br><span class="line">    arr[arr &lt;&#x3D; i] &#x3D; 0</span><br><span class="line">    y_predict&#x3D;arr</span><br><span class="line">    def TN(y_true, y_predict):</span><br><span class="line">        assert len(y_true) &#x3D;&#x3D; len(y_predict)  </span><br><span class="line">        return np.sum((y_true&#x3D;&#x3D;0)&amp;(y_predict&#x3D;&#x3D;0))</span><br><span class="line">    def FP(y_true, y_predict):</span><br><span class="line">        assert len(y_true) &#x3D;&#x3D; len(y_predict)</span><br><span class="line">        return np.sum((y_true&#x3D;&#x3D;0)&amp;(y_predict&#x3D;&#x3D;1))</span><br><span class="line">    cost_temp&#x3D;500*FP(test_label,arr)+10*TN(test_label,arr)</span><br><span class="line">    if cost_temp&lt;cost:</span><br><span class="line">        cost&#x3D;cost_temp </span><br><span class="line">        thresholds_best&#x3D;i</span><br><span class="line">print(cost,thresholds_best)      </span><br><span class="line">#阈值在0.814左右cost最小，最佳。即当概率小于0.814时，车即被判为性能不正常进行检修</span><br></pre></td></tr></table></figure>
<p>最后得出的结果显示，阈值为0.814时，总代价$ cost $最小。也就是，当阈值大于0.814时，车被判为健康状况不良进行检修，对车厂的效率是最高的。</p>
<p>对于这类不同的分类错误会导致不同的惩罚力度时如何训练分类器的问题，除了阈值的筛选，还有一些前沿的解决方法，称为代价敏感的学习方法[<a href="#_edn3">iii]</a>。代价敏感学习的算法研究又可以分成三类：</p>
<p>（1）直接构造一个代价敏感的学习模型；</p>
<p>（2）基于对分类结果的后处理，即按照传统的学习方法学习一个分类模型，然后对其分类结果按照贝叶斯风险理论对结果进行调整，以达到最小的损失。</p>
<p>（3）基于传统的学习模型，通过改变原始训练数据的分布来训练得到代价敏感的模型。</p>
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> <strong>总结</strong></h3>
<p>在本项目中，我们对智能汽车传感器的数据应用了机器学习的方法来判断汽车的健康状况，通过数据清洗、特征选择、模型集成等方法，测试集上的分类的准确率达到94%。同时，在最后一部分，我们根据实际情况对阈值进行重新考量，建立车厂召回汽车的代价函数，让车厂在选择召回汽车的决策中效率最佳。</p>
<hr>
<p>[<a href="#_ednref1">i]</a> 汽车传感器：智能汽车的感知与计算</p>
<p>[<a href="#_ednref2">ii]</a> 机器学习：处理不平衡数据的5个重要技术</p>
<p>[<a href="#_ednref3">iii]</a> 代价敏感分类算法的实验比较。闫明松，周志华。模式识别与人工智能。Vol.18 No.5。Oct 2005</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/16/pdd2/" rel="next" title="与小伙伴们一起完成的对拼多多公司融资和估值分析">
                <i class="fa fa-chevron-left"></i> 与小伙伴们一起完成的对拼多多公司融资和估值分析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/05/18/%E7%AE%A1%E9%81%93%E5%8F%AF%E9%9D%A0%E6%80%A7%E5%88%86%E6%9E%90/" rel="prev" title="文献：管道可靠性分析">
                文献：管道可靠性分析 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Ren Yixin</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#项目背景及意义"><span class="nav-number">1.</span> <span class="nav-text"> 项目背景及意义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关概念"><span class="nav-number">2.</span> <span class="nav-text"> 相关概念</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#汽车传感器智能汽车的感知和计算"><span class="nav-number">2.1.</span> <span class="nav-text"> 汽车传感器：智能汽车的感知和计算</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#机器学习"><span class="nav-number">2.2.</span> <span class="nav-text"> 机器学习</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#汽车传感器数据分析"><span class="nav-number">3.</span> <span class="nav-text"> 汽车传感器数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#数据探索和方法选择"><span class="nav-number">3.1.</span> <span class="nav-text"> 数据探索和方法选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据预处理"><span class="nav-number">3.2.</span> <span class="nav-text"> 数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#区分特征值和标签"><span class="nav-number">3.2.1.</span> <span class="nav-text"> 区分特征值和标签</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#区分数据特征类型"><span class="nav-number">3.2.2.</span> <span class="nav-text"> 区分数据特征类型：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#标签数据转换"><span class="nav-number">3.2.3.</span> <span class="nav-text"> 标签数据转换：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#数据缺失值填充"><span class="nav-number">3.2.4.</span> <span class="nav-text"> 数据缺失值填充：</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#特征工程"><span class="nav-number">3.2.5.</span> <span class="nav-text"> 特征工程：</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#模型设计和集成"><span class="nav-number">3.3.</span> <span class="nav-text"> 模型设计和集成</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#结果分析"><span class="nav-number">4.</span> <span class="nav-text"> 结果分析</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#总结"><span class="nav-number">5.</span> <span class="nav-text"> 总结</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ren Yixin</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">46.6k</span>
  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共46.6k字</span>
</div>

        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
